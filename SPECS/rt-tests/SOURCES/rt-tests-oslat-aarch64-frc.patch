--- a/src/oslat/oslat.c	2023-11-14 12:11:55.699765502 -0800
+++ b/src/oslat/oslat.c	2023-11-14 16:35:46.361706256 -0800
@@ -68,6 +68,35 @@
 {
 	__asm__ __volatile__("mfspr %0, 268\n" : "=r" (*pval));
 }
+# elif defined(__aarch64__)
+#  define relax()          __asm__ __volatile("yield" : : : "memory")
+
+#define arch_measure_counter_mhz
+static unsigned int measure_counter_mhz(void)
+{
+        unsigned int val;
+
+        __asm__ __volatile__("mrs %0, cntfrq_el0" : "=r" (val));
+
+        return val / 1e6;
+}
+
+static inline void frc(uint64_t *pval)
+{
+        /*
+         * This isb() is required to prevent that the counter value
+         * is speculated.
+         */
+        __asm__ __volatile__("isb" : : : "memory");
+        __asm__ __volatile__("mrs %0, cntvct_el0" : "=r" (*pval) :: "memory");
+        /*
+         * This isb() is required to prevent the processor from accessing
+         * memory appearing in program order after the read of the counter
+         * before the counter has been read. Which would skew the counter value
+         * to a later point than intended.
+         */
+        __asm__ __volatile__("isb" : : : "memory");
+}
 # else
 #  error Need frc() for this platform.
 # endif
@@ -118,7 +147,7 @@
 	pthread_t            thread_id;
 
 	/* NOTE! this is also how many ticks per us */
-	unsigned int         cpu_mhz;
+	unsigned int         counter_mhz;
 	cycles_t             int_total;
 	stamp_t              frc_start;
 	stamp_t              frc_stop;
@@ -220,7 +249,8 @@
 	return sched_setaffinity(0, sizeof(cpus), &cpus);
 }
 
-static cycles_t __measure_cpu_hz(void)
+#ifndef arch_measure_counter_mhz
+static cycles_t __measure_counter_hz(void)
 {
 	struct timeval tvs, tve;
 	stamp_t s, e;
@@ -236,13 +266,13 @@
 	return (cycles_t) ((e - s) / sec);
 }
 
-static unsigned int measure_cpu_mhz(void)
+static unsigned int measure_counter_mhz(void)
 {
 	cycles_t m, mprev, d;
 
-	mprev = __measure_cpu_hz();
+	mprev = __measure_counter_hz();
 	do {
-		m = __measure_cpu_hz();
+		m = __measure_counter_hz();
 		if (m > mprev)
 			d = m - mprev;
 		else
@@ -252,10 +282,11 @@
 
 	return (unsigned int) (m / 1000000);
 }
+#endif
 
 static void thread_init(struct thread *t)
 {
-	t->cpu_mhz = measure_cpu_mhz();
+	t->counter_mhz = measure_counter_mhz();
 	t->maxlat = 0;
 	t->overflow_sum = 0;
 	t->minlat = (uint64_t)-1;
@@ -280,7 +311,7 @@
 
 static float cycles_to_sec(const struct thread *t, uint64_t cycles)
 {
-	return cycles / (t->cpu_mhz * 1e6);
+	return cycles / (t->counter_mhz * 1e6);
 }
 
 static void insert_bucket(struct thread *t, stamp_t value)
@@ -288,7 +319,7 @@
 	int index, us;
 	uint64_t extra;
 
-	index = value / t->cpu_mhz;
+	index = value / t->counter_mhz;
 	assert(index >= 0);
 	us = index + 1;
 	assert(us > 0);
@@ -442,7 +473,7 @@
 	calculate(t);
 
 	putfield("Core", t[i].core_i, "d", "");
-	putfield("CPU Freq", t[i].cpu_mhz, "u", " (Mhz)");
+	putfield("Counter Freq", t[i].counter_mhz, "u", " (Mhz)");
 
 	for (j = 0; j < g.bucket_size; j++) {
 		if (j < g.bucket_size-1 && g.output_omit_zero_buckets) {
